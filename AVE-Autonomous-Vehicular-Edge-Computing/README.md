# Mobile-Edge-Computing

## AVE：基于ACO的调度的自主车辆边缘计算框架

### Abstract
随着车载应用的出现，提供所需的计算能力正成为一个至关重要的问题。本文提出了一种用于道路边缘计算的自动车辆边缘（AVE）框架，旨在以分散的方式提高车辆的计算能力。通过管理车辆上的空闲计算资源并有效地使用它们，所提出的AVE框架可以在动态车辆环境中提供计算服务，而不需要部署特定的基础设施。具体而言，本文介绍了支持车辆边缘自主组织的工作流程。提出了有效的工作缓存，以便根据在邻近车辆上收集的信息（包括GPS信息）更好地安排工作。设计了一种基于蚁群优化的调度算法来解决这一作业分配问题。进行了广泛的模拟，模拟结果证明了这种方法优于典型城市和高速公路场景中的竞争方案。

### INTRODUCTION
随着智能车辆的发展，越来越多的计算机应用正在车辆环境中使用。随着智能车辆的发展，越来越多的计算机应用正在车辆环境中使用。这对车辆提出了新的挑战，即如何满足这些应用的计算要求。升级机载计算机是一种选择，但成本很高。云计算是另一种可能的解决方案，其中使用网络远程服务器来满足计算要求。然而，传统的集中式云计算在车辆环境中遭受长延迟和不稳定连接。这极大地降低了体验的质量。例如，增强现实可以通过车辆中的抬头显示提供有用的信息和警告，或者可以提供更好的视野。然而，AR具有高计算要求，这通常超出单个车辆的计算能力; 此外，由于AR还需要快速处理，因此在路上直接使用传统云服务对于AR是不现实的，因为高延迟。可能在车辆环境中有用的计算密集型应用的其他示例包括语音识别和自然语言处理，其预期在用于辅助驾驶员和乘客的应用中变得更广泛地使用。

边缘计算是一种更适合在车辆环境中增强计算能力的解决方案。车辆之间的通信可以基于专用短程通信（DSRC）或设备到设备通信来实现，这可以大大提高通信质量。此外，车辆在任何时候都没有运行计算密集型应用程序。因此，通过有效地管理车辆资源，可以实现支持这些应用的低延迟边缘云环境。已经针对用于车辆环境的云计算系统进行了若干相关研究，例如机场的数据中心，车轮上的图形和云交通系统（CTS）。但是，这些方案具有各种限制，例如仅可用于静态场景，专用于特定应用程序或需要基于基础架构的集中控制。如何在高度动态的车辆环境中有效利用车辆资源以及如何为所有应用提供通用框架的问题是非平凡的，并且从作者所知的最佳状态尚未正式研究。

为了解决上述问题，我们提出了一种用于道路边缘计算的自主车辆边缘（AVE）框架。 在此框架中，我们引入了一个工作流来支持车载云的自治组织。 提出了有效的工作缓存，以便根据在邻近车辆上收集的信息（包括GPS信息）更好地安排工作。 提出了一种基于蚁群优化（ACO）的调度算法来解决分配问题。 使用模拟流量和IEEE 802.11p网络进行广泛的模拟。这项工作的主要贡献如下：  
* 1）我们为AVE提出了一种模块化架构，以支持广义任务卸载。 在我们的框架中，对应用程序的要求保持最小。  
* 2）我们设计了允许卸载和调度的程序，而无需集中控制，因此可以以最小的部署成本应用它们。  
* 3）我们进一步提出了一种基于ACO的调度算法，通过快速收敛来解决NP-hard作业分配问题，从而在10次迭代中实现了90％以上的最优结果。  
* 4）最后，我们使用高速公路和城市情景的实际交通数据进行广泛的评估。 我们的仿真结果证明了所提出的框架优于现有方案的优势。  

本文的其余部分安排如下。 第二部分分析了该框架的动机，并概述了拟议的工作卸载方法。 第三节定义了拟议框架的组成部分。 第四节介绍了工作流程并描述了工作分配问题。 第五节解释了基于ACO的调度算法，用于解决分配问题。 然后通过模拟评估框架，如第六节所述。 第七节介绍了以前的相关研究，我们在第八节中总结了这篇论文。

### PROBLEM ANALYSIS
#### A. Motivation: Vehicle Applications
车辆应用程序可根据其特征分为三个级别：关键应用程序（CA），高优先级应用程序（HPA）和低优先级应用程序（LPA），如表I所示。CA是车辆系统或安全相关应用的核心应用。由于它们对车辆和乘客的重要性，CA具有最高优先级，并且必须完美地执行而不依赖于车辆环境中的不稳定连接。此外，由于CA通常由车辆制造商开发，因此车辆的车载系统应始终设计为具有足够（如果不是足够的）容量以满足其资源需求。因此，CA被认为完全在AVE之外执行。

![image](https://github.com/qpointwang/Mobile-Edge-Computing/blob/master/AVE-Autonomous-Vehicular-Edge-Computing/table1.png)

其余应用程序根据其用途分为高优先级应用程序（HPA）和低优先级应用程序（LPA）。HPA包括与驾驶相关的应用和可选的安全增强应用，例如，用于驾驶员的路由和信息服务。这些应用程序很重要但不是强制性的，这意味着允许故障和延迟，但会给驾驶员带来不便。典型的HPA包括抬头显示器，视野增强和道路感应。越来越多的新车配备了这样的应用。为了适应这些新兴的HPA服务，制造商正在为其板载系统设计一些计算容量余量。

LPA是一类对驾驶员和乘客不太重要的应用程序。 例如，语音识别是一种有趣的应用程序，它允许驾驶员发出各种命令而不会分心驾驶。Apple's CarPlay采用了这一概念，其实现依赖于通过蜂窝网络连接的智能手机和云计算。其他多媒体应用，例如视频处理，也已经被提出用于车辆。随着自动驾驶车辆的出现趋势，用户变得能够将他们的注意力从驾驶转移到诸如娱乐之类的其他活动。基于云的视频游戏将为乘客或免费驾驶员提供更好的旅行体验。随着智能车辆的进一步发展，将出现越来越多的HPA和LPA。请注意，HPA和LPA可以互换; 即，HPA可以是某些车辆的LPA，而LPA可以是某些车辆的HPA。

固有的问题是如何满足LPA和HPA在车辆中不断增加的计算需求。 基于有效利用现有计算资源的解决方案可以减轻新车辆应用的部署负担，而不是替换设备甚至整个车辆。

#### B. Methodology: Cloud and Edge Computing
通过将本地工作负载卸载到远程云，设备的所有者可以免于升级和维护其他硬件的需要。这个概念很快被移植到移动环境中，在那里它也被称为移动云计算（MCC）。 MCC为移动设备提供了良好的解决方案，移动设备通常在计算能力方面表现不佳并且需要高成本升级。但是，在移动方案中，卸载面临诸如网络连接不稳定，高延迟和网络数据费用等挑战。在车辆环境中，这些问题中的一些甚至更严重。车辆的移动性远远高于手持设备的移动性，这显着缩短了与路边单元（RSU）等定点基础设施的链路持续时间。此外，与主要在城市地区漫游的手持设备不同，车辆通常位于农村地区，基础设施很少部署，远程云的互联网连接不如城市地区。由于这些限制，云计算难以在车辆环境中使用。

移动边缘计算（MEC）是解决这些问题的另一种选择。该概念涉及将计算资源放置在网络的逻辑极端，例如，接入点，RSU，基站，或甚至用户的设备，而不是仅依赖于集中式云。 通过这种方式，MEC使应用程序能够实时响应。区分云计算和边缘计算与其他方法的主要区别在于“虚拟化”资源的能力，这意味着资源不是以物理形式（例如CPU和HDD）提供，而是以每次和每次使用的方式提供。 这些方法允许为消费者提供更灵活的服务，降低升级和维护成本。

移动边缘计算（MEC）是解决这些问题的另一种选择。该概念涉及将计算资源放置在网络的逻辑极端，例如，接入点，RSU，基站，或甚至用户的设备，而不是仅依赖于集中式云。 通过这种方式，MEC使应用程序能够实时响应。区分云计算和边缘计算与其他方法的主要区别在于“虚拟化”资源的能力，这意味着资源不是以物理形式（例如CPU和HDD）提供，而是以每次和每次使用的方式提供。 这些方法允许为消费者提供更灵活的服务，降低升级和维护成本。

我们的目标是在车辆环境中实现本地“云”理念，基于以下属性：  
* 1）可共享资源：除了CA使用的计算资源之外，一些资源仍然可用于HPA/LPA。当这些应用程序未运行时（例如，导航应用程序在完成路由计算之后变为空闲），该资源子集处于空闲状态并且可以被共享。  
* 2）运动模式：虽然车辆相对于静止的基础设施具有较高的速度，但是其连杆持续时间较短，但在同一道路上以相同方向行驶的两辆车之间的速度差异要小得多;因此，这些车辆之间的链路持续时间变得更长。  
* 3）能源：MEC的一项艰巨挑战是移动设备的电池寿命有限。协助他人并非“免费”，因为它会消耗主机设备的能量。相比之下，车辆具有更大的电池存储，并且与驾驶期间消耗的总能量相比，车载系统的能量成本是微不足道的。  
* 4）激励：参与这样的资源共享框架对服务提供者和用户都是有益的。服务提供商可以降低基础架构部署成本。用户可以以空闲资源为代价享受低延迟计算服务。此外，服务提供商甚至可能为用户的共享资源付费。  

框架设计，自组织方法和分布式环境中的调度存在挑战。先前已对车辆环境中的资源共享进行了研究。然而，就作者所知，没有为一般应用提出解决方案，也没有提出以完全分布式方式运行的解决方案。

#### C. Offloading and Virtualization（卸载和虚拟化）
卸载是将工作负载迁移到其他计算机进行处理的过程;我们将这些工作负载定义为本文中的jobs。本文中的"Job"是一个通用术语;除第III-C节所述的情况外，不推定任何详细的特征。卸载是拟议框架的一个基本方面。 它可以在各种级别执行，例如功能，任务，应用程序和虚拟机。在卸载方面已经完成了大量的工作。一个典型的提议是CloneCloud，它专注于如何拆分工作负载的执行并将它们移动到另一台机器。本文借用这个概念，并不会推倒重来。相反，我们将专注于处理器发现和作业调度。虽然本文概括了工作量概念，但考虑了以下因素：  
* 1）传输数据的大小：由于网络带宽在车辆环境中受到限制，因此要传输的数据量是性能的一个关键因素。  
* 2）主机要求：某些作业需要特定的软件或硬件。 在传统的云计算中，这不是问题，因为云服务器始终可以满足这些要求。 但是，某些节点可能无法满足这些要求。  
* 3）重要性：并非所有工作对用户都有同等的好处。 一些工作（例如，来自HPA的工作）具有更高的优先级，并且应该尽最大努力来完成它们。  

虚拟化是计算资源的抽象，通常是具有相关存储和网络连接的虚拟机。为了更好地虚拟化（即，更好地利用可用计算资源），在处理节点(processing node)上的VM中执行卸载作业的处理。该VM具有两个功能：首先，它包括对workload的必需支持，例如操作系统（OS）和运行时库;第二，它虚拟化或管理剩余资源，不包括CA占用的资源，以便CA的执行与LPA/HPA的执行隔离，并且可以保证CA的优先级。 该虚拟机的虚拟化的资源是什么将利用本文提出的框架安排。上述卸载过程如图1所示。

![image](https://github.com/qpointwang/Mobile-Edge-Computing/blob/master/AVE-Autonomous-Vehicular-Edge-Computing/fig1.png)

### SYSTEM OVERVIEW
#### A. Roles of Nodes
我们将参与框架的每辆车称为节点。每个作业由一个节点生成并由一个节点处理。这两个节点可以是相同的;即，生成作业的节点也可以处理该作业。在这种情况下，我们说该作业是在本地处理的。 如果生成作业的节点无法直接到达有助于处理作业的节点，则需要其他节点来帮助在它们之间转发数据。 为方便起见，本文分别将这三种类型的节点称为请求者，处理器和转发器。请注意，此分类不是永久性的，仅适用于特定作业。车辆可以是一个作业的处理器，同时也是另一个作业的请求者，它没有足够的处理能力。

#### B. Architecture of Proposed Framework
与其他客户端-服务器体系结构一样，此框架中的软件包括客户端应用程序和相应的服务器端应用程序，称为应用程序模块和后端模块，如图2所示。应用程序在本机操作系统上运行，管理其优先级和可用资源;后端在VM中运行，由AVE框架管理。我们引入一个管理器模块（在图2中突出显示）作为中间件来收集来自其他两个模块的信息，作业和结果，并进行卸载和作业分配决策。

![image](https://github.com/qpointwang/Mobile-Edge-Computing/blob/master/AVE-Autonomous-Vehicular-Edge-Computing/fig2.png)

在该车辆开始在道路上行驶之前，该框架的组件部署在每个车辆上。管理器模块预先安装在每辆车上，最好由车载系统供应商预安装。用户选择并安装应用程序。这样做的典型方法是从Internet安装应用程序; 但是，应用程序的安装方式和方式超出了本文的范围。后端可以与相应的应用程序一起安装（例如，用户可能想要可以在车辆上本地运行的应用程序）或独立部署（例如，公司可以在用户的车辆上部署后端以在路上提供服务）。

管理器模块由三个子模块组成：作业队列模块，资源管理模块和调度模块。作业队列模块为应用程序提供作业卸载接口，收集作业并在满足要求（在第IV节中讨论）时将它们放入调度程序中。资源管理模块控制后端可以使用的可用资源。请注意，安全，监视和紧急报告等CA任务不会卸载，并且在本地以最高优先级进行处理。除了CA所占用的资源外，其余资源可供后端使用。调度模块是管理器的核心。调度模块负责与其他节点通信，进行分配决策，发送作业和接收结果。在所提出的框架中，还需要全球定位系统（GPS）设备来调度模块以获得车辆的当前地理位置和速度。由于GPS设备被广泛安装，因此这一要求微不足道。

在我们的框架中建立的网络使用专用的短程通信（DSRC）标准，例如IEEE802.11p。这种类型的通信使得能够在不建立基本服务集的情况下快速建立链路。这减少了将数据发送到其他车辆所产生的开销。

#### C. Jobs
每个卸载的工作负载称为job。 卸载的工作负载可能发生在各种级别，例如功能，应用程序和虚拟机。为了符合这种多样性，这里将工作视为一般化实体。但是，对于用于调度的实际workload的建模，在我们的上下文中假设以下job特征：  
* 1）无上下文：这是在另一台机器上卸载和执行作业的基本要求。作业所依赖的资源文件要么在卸载之前分布在后端，要么被视为作业数据的一部分，并在卸载期间发送。这个特性意味着在卸载到管理器模块之前，应该在应用程序内处理作业的依赖性。应用程序用于分离作业的实现超出了本文的范围。但我们建议：对于依赖于另一个作业完成的作业，应用程序可以选择逐个卸载它们，每个都返回上一个作业的结果，或者将所有顺序作业打包成一个较大的独立作业。无论选择何种方法，缓存作业之间都不存在依赖关系，并且可以单独调度每个作业。例如，在CloneCloud情况下，每个作业都是一个挂起的线程，其所有相关的内存数据都传输到处理主机。
* 2）效用：不同的job通常对用户体验产生不同的影响，这些影响因完成时间而异。这里考虑了效用因子。每个作业都带有一个实用程序函数，它将完成时间映射到称为实用程序的累积实数值。该实用程序还结合了工作的重要性。
* 3）主机指定：我们假设每个节点不一定具备能够处理所有作业所需的所有功能。处理主机的要求也是拟议框架中考虑的因素之一。
* 4）简介(brief)：在分布式环境中，每个车辆必须向潜在的处理器提供关于其所请求的作业的一些信息，以用于处理时间估计和进一步调度。在带宽限制的车辆环境中，在这种查询中传输整个作业是不现实的。相反，每个应用程序都需要指定少量参数（我们称之为简要参数）来描述作业的工作量。这些参数的内容和格式由应用程序和相应的后端确定。

#### D. Neighbor Availability Index(邻居可用性指数)
为了帮助车辆以分布式方式做出决策，引入了称为邻居可用性指数（NAI）的值.NAI可用于指示在请求者的可到达区域内有多少潜在的辅助车辆。 虽然它们的可用资源可能不同，但这仍然可以作为对附近资源的粗略估计。 每辆车计算其NAI为可用于表示有多少可能的协助：  

![image](https://github.com/qpointwang/Mobile-Edge-Computing/blob/master/AVE-Autonomous-Vehicular-Edge-Computing/NAI.png)

这里，“idle”意味着邻居的资源管理器不使用它管理的可用资源处理任何作业。k指定邻居的跳数。因为根据现有研究，通过超过2跳的中继的通信是不稳定的，所以在NAI计算和进一步调度中忽略超过2跳的节点。φ是表示随着跳数增加而资源可用性衰落的因素。这里的“衰落”指的是随着跳数的增加，传输开销和失去连接的概率增加，这导致卸载的收益减少。在我们的模拟场景中测试，φ= 0.8是合适的，但是最合适的值可能在不同的实际情况中不同。

为了在需要时计算NAI，AVE在每辆车上建立一个NAI表以存储所需信息。表中的条目的格式为<车辆ID，空闲状态，跳数，到期时间>，并且当达到其到期时间时，将自动删除条目。更新此表的过程将在第IV节中进一步讨论。

### WORKFLOW

![image](https://github.com/qpointwang/Mobile-Edge-Computing/blob/master/AVE-Autonomous-Vehicular-Edge-Computing/fig3.png)

AVE框架的工作流程由两部分组成：主动定期信标和主动流程(active periodic beaconing and proactive flows)。 flow表示处理作业从到达到返回结果的过程。在这个框架中，我们将流程划分为四个主要阶段：作业缓存，发现，调度和数据传输，如图3所示。信息的细节和流程的阶段在本节的其余部分进行了解释。

#### A. Beaconing
AVE框架使用beacon消息来帮助车辆获取有关附近可用资源的信息。每个车辆以配置的间隔周期单独广播短beacon消息（本文中考虑的默认值为10秒）。这些beacon消息不会被转发。 AVE信标消息包含以下信息：
* 1）源车辆的ID，
* 2）它的速度矢量，
* 3）它的空闲状态，和
* 4）源车辆的空闲1跳邻居的ID列表。

请注意，如果4）中的列表太长，则只包含几个随机选择的条目，其余条目将被忽略。 我们在实现中选择50作为所选条目的最大数量，这在大多数情况下已足够。

该beacon消息的任何接收者都可以提取其携带的信息。在接收到beacon时，接收器计算其自身与发送器之间的速度差为|v-v0|，其中v是接收速度，v0是接收器的速度。如果该速度差大于预设值，该值在默认设计中设定为15米/秒(54公里/小时，大约是两辆车在城市街道上正交方向行驶时的速度差)，则接收器认为其与源节点的链接不稳定并忽略此信标消息。否则，接收方使用以下规则将消息中提到的每个车辆记录到其NAI表中：
* 1）如果车辆不在表中，则为其创建条目。 对于该beacon的源车辆，跳数设置为1，或者对于源车辆的邻居列表中的车辆，跳数设置为2。 过期时间更新为tnow + D，其中tnow是当前时间，D是可配置的持续时间（默认值是beacon间隔）。
* 2）如果车辆在表中并且beacon的源车辆被记录为表中的2跳邻居，则跳数改变为1并且相应地更新到期时间; 否则，只更新到期时间
* 3）否则，不对表格进行修改。

#### B. Job Caching
管理器模块不是在到达时立即调度和上载每个作业，而是运行队列来缓存作业，其中每个缓存持续时间称为caching window。缓存的主要原因是避免多个同时发现进程和数据传输，这不仅会导致作业相互竞争有限的带宽，而且还可能使返回的消息无效。 这是因为可用资源可能会因卸载早期作业而发生变化。此外，缓存允许更好的分配决策并降低发现频率。 当收集更多作业时，我们可以通过考虑作业优先级和节点利用率状态，更有效地为每个作业找到最佳处理器。

当第一个作业在tfirst时刻到达当前window时，设置结束时间为tend=tfirst+Q/(NAI+1)。这里，Q是该请求者处理其当前处理队列中所有作业的估计时间，如果要在当前时间本地处理新作业，也可以将其视为“排队时间”。特别是，如果此请求者空闲，则Q = 0。

当满足以下两个条件时，缓存持续时间结束：
* 1）前一个流程已完成数据传输，并且
* 2）缓存作业的数量大于(NAI+1)或者时间超过tend。

一般的想法如下：如果附近有足够的可用车辆，那么我们想要缓存当前边缘可以处理的多个作业，从而可以减少发现的频率并且可以找到更好的分配。但是，如果资源充足（即，如果NAI很高），我们不希望工作等待太长时间。

 为了消除稀疏区域中无用缓存所产生的开销，如果当前NAI为0，则跳过缓存。当发生这种情况时，流程终止。 所有工作都按照先到先得的方式在当地进行处理。

#### C. Discovery
当缓存时间到期时，当前作业队列被锁定并且发现阶段开始。在发现阶段期间，请求者首先广播边缘请求消息（EREQ）以发现潜在的附近处理器。此EREQ包含请求者的ID，其速度向量以及在上一个缓存窗口期间缓存的作业的brief。

每个接收器检查EREQ中包含的速度矢量，并使用针对beacon描述的相同规则计算速度差。 如果速度差太大，则忽略此EREQ。否则，所有单跳接收器都会将EREQ转发给附近的车辆;即，他们成为这个请求者的转发者。此外，对于与接收器兼容的每个作业，将具有作业brief的查询发送到资源管理器。 然后，资源管理器要求相应的后端生成bid。bid是对完成作业所需时间的估计，这是根据必要的计算（在作业条目中提供的简要说明中），车辆的处理能力以及愿意去分享的可用计算资源确定的。Bij表示来自节点i的作业j的bid。在所有查询完成后，如果有任何出价，则接收方发回边缘响应消息(EREP)。EREP包括响应车辆的ID和每个作业的上述出价。如果响应车辆是请求者的邻居，则直接发回EREP。 否则，EREP将通过转发器发送给请求者。在该框架中使用相同的路由（即，节点将其EREP发送到将相应的EREQ转发到其的节点），因为假设网络拓扑在如此短的持续时间内保持相同是合理的。为了避免来自两个不同请求者的请求冲突，每个接收器保留承诺的资源一小段时间（默认值为50毫秒），在此期间它暂停响应请求。但是，转发者不受此规则的限制。

请求者等待很短的时间来收集确认。等待时间设置为2跳传输的最大往返延迟。如果无法估计此往返延迟，则将设置手动配置的时间(默认值为50ms)。在等待时间到期之后，请求者基于收集的信息开始作业调度。

#### D. Scheduling
调度问题场景可以描述如下：在缓存和发现之后，我们有一组有限的作业和一组有限的节点。每个作业将被发送到其中一个要处理的节点。首先，必须在处理作业之前完成传输。 为了减少平均传输时间，每个作业的传输仅在前一个作业的传输完成后才开始。由于车辆环境中可用的带宽有限，传输时间不可忽略。当分配的处理器已收到作业的所有数据时，它会立即将作业放入处理队列。按先到先得的顺序逐个处理排队的作业。在任何给定的时刻，只有一个作业被执行以允许它利用所有可用资源。当作业的处理结束时，作业的结果被发送回请求者。收到结果后，假定作业已完成，并获得相应的效用。

该调度方法试图通过确定要发送的作业的顺序和每个作业的目的节点（即，对于每个发送的作业，选择哪个节点以帮助处理）来最大化总效用。这个问题可以看作是一个两阶段的混合流水车间问题，从强烈的意义上讲是NP难的。调度问题的制定和提出的解决方案在第V节中描述。在调度完成之后，请求者确定要传输的作业序列和每个作业的目标节点。 然后，数据传输立即开始。

分配完成后，使用与EREQ相同的规则广播短通知消息。 此通知包含在调度期间获得的分配结果。 这是为了通知分配的节点停止发送EREP并等待已分配给它们的作业到达。

#### E. Data Transmission
卸载过程在调度阶段结束后开始。由于分配算法的运行时间很短，因此可以合理地假设在作业发现阶段期间网络结构与网络结构相比不会发生变化。因此，数据可以沿着EREQ使用的相同路径传输。在调度过程中确定传输顺序，如第IV-D节中所讨论的。

在接收到一个作业的所有数据后，处理器将该作业添加到其处理队列的末尾。排队的作业逐个处理。对于每个作业，资源管理模块将相应的后端带入其托管VM以供执行，然后等待，直到后端完成当前作业。在执行期间，后端可以利用受管VM的承诺资源。

作业过程完成后，结果将发送回请求者。由于我们在本文中没有关注ad hoc路由，因此我们在实现中使用传统的路由协议称为ad hoc按需距离矢量(AODV)路由。请注意，AODV不是唯一的选择，其他单播协议，例如可预测的广播计算(PBR)在这里也是可行的。此外，如果两个车辆之间的路由路径可用（例如，由其他车载网络应用程序建立），我们可以直接利用该路径。

### V. SCHEDULING ALGORITHM
在本节中，解释了需要其他节点帮助的每个节点的基于ACO的调度算法。 AVE是一个分散的平台，每个节点根据提出的调度算法单独为自己的作业做出调度决策。

#### A. Problem Formulation
![image](https://github.com/qpointwang/Mobile-Edge-Computing/blob/master/AVE-Autonomous-Vehicular-Edge-Computing/table2.png)


#### B. ACO-Based Algorithm
由于缺乏完整的算法来解决问题，我们转向启发式算法，它可以在合理的运行时间内产生接近最优的解。 在本文中，我们使用基于ACO的作业调度。
* 1）蚁群优化：ACO是一种受到寻找食物途径的蚂蚁行为启发的方法。在自然界中，当一只蚂蚁找到食物时，它会返回到殖民地时放下一条信息素踪迹，然后吸引其他蚂蚁沿着它的路径行进。由于信息素随着时间的推移而蒸发，随着蚂蚁向后移动，较长的踪迹往往会失去更多的信息素，这使得它的吸引力降低。相反，较短的路径将保留更多的信息素并吸引更多的蚂蚁跟随。 这些额外吸引的蚂蚁也会沉积更多的信息素，而这种积极的反馈最终将通过迭代吸引所有蚂蚁使用最短的路径。  
当这个概念应用于数学问题时，术语“轨迹”通常指的是状态转换。一系列连续转换将从起始状态（空解）引导到结束状态（完整解），从而为该问题提供可行的解决方案。通常，ACO算法有四个步骤：
	* 1）初始化：初始化所有路径的信息素水平。
	* 2）解决方案构造：将状态设置为起始状态（从空解决方案）。 然后，通过信息素水平给出的概率重复选择到下一个状态的路径，直到达到结束状态。
	* 3）更新：更新路径的信息素水平：
		* a）根据蒸发速率降低所有信息素水平，并且
		* b）增加蚂蚁选择的所有踪迹的信息素水平。
	* 4）终止：如果满足终止条件，则返回最佳解决方案。 否则，返回步骤2。  
先前已采用ACO概念来解决分配问题和调度问题，并获得满意的结果。 接下来，我们将展示如何使用ACO解决AVE中的作业调度问题。