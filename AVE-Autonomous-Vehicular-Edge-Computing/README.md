# Mobile-Edge-Computing

## AVE：基于ACO的调度的自主车辆边缘计算框架

### Abstract
随着车载应用的出现，提供所需的计算能力正成为一个至关重要的问题。本文提出了一种用于道路边缘计算的自动车辆边缘（AVE）框架，旨在以分散的方式提高车辆的计算能力。通过管理车辆上的空闲计算资源并有效地使用它们，所提出的AVE框架可以在动态车辆环境中提供计算服务，而不需要部署特定的基础设施。具体而言，本文介绍了支持车辆边缘自主组织的工作流程。提出了有效的工作缓存，以便根据在邻近车辆上收集的信息（包括GPS信息）更好地安排工作。设计了一种基于蚁群优化的调度算法来解决这一作业分配问题。进行了广泛的模拟，模拟结果证明了这种方法优于典型城市和高速公路场景中的竞争方案。

### INTRODUCTION
随着智能车辆的发展，越来越多的计算机应用正在车辆环境中使用。随着智能车辆的发展，越来越多的计算机应用正在车辆环境中使用。这对车辆提出了新的挑战，即如何满足这些应用的计算要求。升级机载计算机是一种选择，但成本很高。云计算是另一种可能的解决方案，其中使用网络远程服务器来满足计算要求。然而，传统的集中式云计算在车辆环境中遭受长延迟和不稳定连接。这极大地降低了体验的质量。例如，增强现实可以通过车辆中的抬头显示提供有用的信息和警告，或者可以提供更好的视野。然而，AR具有高计算要求，这通常超出单个车辆的计算能力; 此外，由于AR还需要快速处理，因此在路上直接使用传统云服务对于AR是不现实的，因为高延迟。可能在车辆环境中有用的计算密集型应用的其他示例包括语音识别和自然语言处理，其预期在用于辅助驾驶员和乘客的应用中变得更广泛地使用。

边缘计算是一种更适合在车辆环境中增强计算能力的解决方案。车辆之间的通信可以基于专用短程通信（DSRC）或设备到设备通信来实现，这可以大大提高通信质量。此外，车辆在任何时候都没有运行计算密集型应用程序。因此，通过有效地管理车辆资源，可以实现支持这些应用的低延迟边缘云环境。已经针对用于车辆环境的云计算系统进行了若干相关研究，例如机场的数据中心，车轮上的图形和云交通系统（CTS）。但是，这些方案具有各种限制，例如仅可用于静态场景，专用于特定应用程序或需要基于基础架构的集中控制。如何在高度动态的车辆环境中有效利用车辆资源以及如何为所有应用提供通用框架的问题是非平凡的，并且从作者所知的最佳状态尚未正式研究。

为了解决上述问题，我们提出了一种用于道路边缘计算的自主车辆边缘（AVE）框架。 在此框架中，我们引入了一个工作流来支持车载云的自治组织。 提出了有效的工作缓存，以便根据在邻近车辆上收集的信息（包括GPS信息）更好地安排工作。 提出了一种基于蚁群优化（ACO）的调度算法来解决分配问题。 使用模拟流量和IEEE 802.11p网络进行广泛的模拟。这项工作的主要贡献如下：  
* 1）我们为AVE提出了一种模块化架构，以支持广义任务卸载。 在我们的框架中，对应用程序的要求保持最小。  
* 2）我们设计了允许卸载和调度的程序，而无需集中控制，因此可以以最小的部署成本应用它们。  
* 3）我们进一步提出了一种基于ACO的调度算法，通过快速收敛来解决NP-hard作业分配问题，从而在10次迭代中实现了90％以上的最优结果。  
* 4）最后，我们使用高速公路和城市情景的实际交通数据进行广泛的评估。 我们的仿真结果证明了所提出的框架优于现有方案的优势。  

本文的其余部分安排如下。 第二部分分析了该框架的动机，并概述了拟议的工作卸载方法。 第三节定义了拟议框架的组成部分。 第四节介绍了工作流程并描述了工作分配问题。 第五节解释了基于ACO的调度算法，用于解决分配问题。 然后通过模拟评估框架，如第六节所述。 第七节介绍了以前的相关研究，我们在第八节中总结了这篇论文。

### PROBLEM ANALYSIS
#### A. Motivation: Vehicle Applications
车辆应用程序可根据其特征分为三个级别：关键应用程序（CA），高优先级应用程序（HPA）和低优先级应用程序（LPA），如表I所示。CA是车辆系统或安全相关应用的核心应用。由于它们对车辆和乘客的重要性，CA具有最高优先级，并且必须完美地执行而不依赖于车辆环境中的不稳定连接。此外，由于CA通常由车辆制造商开发，因此车辆的车载系统应始终设计为具有足够（如果不是足够的）容量以满足其资源需求。因此，CA被认为完全在AVE之外执行。
![image](https://github.com/qpointwang/Mobile-Edge-Computing/blob/master/AVE-Autonomous-Vehicular-Edge-Computing/table1.png)

其余应用程序根据其用途分为高优先级应用程序（HPA）和低优先级应用程序（LPA）。HPA包括与驾驶相关的应用和可选的安全增强应用，例如，用于驾驶员的路由和信息服务。这些应用程序很重要但不是强制性的，这意味着允许故障和延迟，但会给驾驶员带来不便。典型的HPA包括抬头显示器，视野增强和道路感应。越来越多的新车配备了这样的应用。为了适应这些新兴的HPA服务，制造商正在为其板载系统设计一些计算容量余量。

LPA是一类对驾驶员和乘客不太重要的应用程序。 例如，语音识别是一种有趣的应用程序，它允许驾驶员发出各种命令而不会分心驾驶。Apple's CarPlay采用了这一概念，其实现依赖于通过蜂窝网络连接的智能手机和云计算。其他多媒体应用，例如视频处理，也已经被提出用于车辆。随着自动驾驶车辆的出现趋势，用户变得能够将他们的注意力从驾驶转移到诸如娱乐之类的其他活动。基于云的视频游戏将为乘客或免费驾驶员提供更好的旅行体验。随着智能车辆的进一步发展，将出现越来越多的HPA和LPA。请注意，HPA和LPA可以互换; 即，HPA可以是某些车辆的LPA，而LPA可以是某些车辆的HPA。

固有的问题是如何满足LPA和HPA在车辆中不断增加的计算需求。 基于有效利用现有计算资源的解决方案可以减轻新车辆应用的部署负担，而不是替换设备甚至整个车辆。

#### B. Methodology: Cloud and Edge Computing
通过将本地工作负载卸载到远程云，设备的所有者可以免于升级和维护其他硬件的需要。这个概念很快被移植到移动环境中，在那里它也被称为移动云计算（MCC）。 MCC为移动设备提供了良好的解决方案，移动设备通常在计算能力方面表现不佳并且需要高成本升级。但是，在移动方案中，卸载面临诸如网络连接不稳定，高延迟和网络数据费用等挑战。在车辆环境中，这些问题中的一些甚至更严重。车辆的移动性远远高于手持设备的移动性，这显着缩短了与路边单元（RSU）等定点基础设施的链路持续时间。此外，与主要在城市地区漫游的手持设备不同，车辆通常位于农村地区，基础设施很少部署，远程云的互联网连接不如城市地区。由于这些限制，云计算难以在车辆环境中使用。

移动边缘计算（MEC）是解决这些问题的另一种选择。该概念涉及将计算资源放置在网络的逻辑极端，例如，接入点，RSU，基站，或甚至用户的设备，而不是仅依赖于集中式云。 通过这种方式，MEC使应用程序能够实时响应。区分云计算和边缘计算与其他方法的主要区别在于“虚拟化”资源的能力，这意味着资源不是以物理形式（例如CPU和HDD）提供，而是以每次和每次使用的方式提供。 这些方法允许为消费者提供更灵活的服务，降低升级和维护成本。

移动边缘计算（MEC）是解决这些问题的另一种选择。该概念涉及将计算资源放置在网络的逻辑极端，例如，接入点，RSU，基站，或甚至用户的设备，而不是仅依赖于集中式云。 通过这种方式，MEC使应用程序能够实时响应。区分云计算和边缘计算与其他方法的主要区别在于“虚拟化”资源的能力，这意味着资源不是以物理形式（例如CPU和HDD）提供，而是以每次和每次使用的方式提供。 这些方法允许为消费者提供更灵活的服务，降低升级和维护成本。

我们的目标是在车辆环境中实现本地“云”理念，基于以下属性：  
* 1）可共享资源：除了CA使用的计算资源之外，一些资源仍然可用于HPA/LPA。当这些应用程序未运行时（例如，导航应用程序在完成路由计算之后变为空闲），该资源子集处于空闲状态并且可以被共享。  
* 2）运动模式：虽然车辆相对于静止的基础设施具有较高的速度，但是其连杆持续时间较短，但在同一道路上以相同方向行驶的两辆车之间的速度差异要小得多;因此，这些车辆之间的链路持续时间变得更长。  
* 3）能源：MEC的一项艰巨挑战是移动设备的电池寿命有限。协助他人并非“免费”，因为它会消耗主机设备的能量。相比之下，车辆具有更大的电池存储，并且与驾驶期间消耗的总能量相比，车载系统的能量成本是微不足道的。  
* 4）激励：参与这样的资源共享框架对服务提供者和用户都是有益的。服务提供商可以降低基础架构部署成本。用户可以以空闲资源为代价享受低延迟计算服务。此外，服务提供商甚至可能为用户的共享资源付费。  

框架设计，自组织方法和分布式环境中的调度存在挑战。先前已对车辆环境中的资源共享进行了研究。然而，就作者所知，没有为一般应用提出解决方案，也没有提出以完全分布式方式运行的解决方案。

#### C. Offloading and Virtualization（卸载和虚拟化）
卸载是将工作负载迁移到其他计算机进行处理的过程;我们将这些工作负载定义为本文中的jobs。本文中的"Job"是一个通用术语;除第III-C节所述的情况外，不推定任何详细的特征。卸载是拟议框架的一个基本方面。 它可以在各种级别执行，例如功能，任务，应用程序和虚拟机。在卸载方面已经完成了大量的工作。一个典型的提议是CloneCloud，它专注于如何拆分工作负载的执行并将它们移动到另一台机器。本文借用这个概念，并不会推倒重来。相反，我们将专注于处理器发现和作业调度。虽然本文概括了工作量概念，但考虑了以下因素：  
* 1）传输数据的大小：由于网络带宽在车辆环境中受到限制，因此要传输的数据量是性能的一个关键因素。  
* 2）主机要求：某些作业需要特定的软件或硬件。 在传统的云计算中，这不是问题，因为云服务器始终可以满足这些要求。 但是，某些节点可能无法满足这些要求。  
* 3）重要性：并非所有工作对用户都有同等的好处。 一些工作（例如，来自HPA的工作）具有更高的优先级，并且应该尽最大努力来完成它们。  

虚拟化是计算资源的抽象，通常是具有相关存储和网络连接的虚拟机。为了更好地虚拟化（即，更好地利用可用计算资源），在处理节点(processing node)上的VM中执行卸载作业的处理。该VM具有两个功能：首先，它包括对workload的必需支持，例如操作系统（OS）和运行时库;第二，它虚拟化或管理剩余资源，不包括CA占用的资源，以便CA的执行与LPA/HPA的执行隔离，并且可以保证CA的优先级。 该虚拟机的虚拟化的资源是什么将利用本文提出的框架安排。上述卸载过程如图1所示。
![image](https://github.com/qpointwang/Mobile-Edge-Computing/blob/master/AVE-Autonomous-Vehicular-Edge-Computing/fig1.png)

### SYSTEM OVERVIEW
#### A. Roles of Nodes
我们将参与框架的每辆车称为节点。每个作业由一个节点生成并由一个节点处理。这两个节点可以是相同的;即，生成作业的节点也可以处理该作业。在这种情况下，我们说该作业是在本地处理的。 如果生成作业的节点无法直接到达有助于处理作业的节点，则需要其他节点来帮助在它们之间转发数据。 为方便起见，本文分别将这三种类型的节点称为请求者，处理器和转发器。请注意，此分类不是永久性的，仅适用于特定作业。车辆可以是一个作业的处理器，同时也是另一个作业的请求者，它没有足够的处理能力。

#### B. Architecture of Proposed Framework
与其他客户端-服务器体系结构一样，此框架中的软件包括客户端应用程序和相应的服务器端应用程序，称为应用程序模块和后端模块，如图2所示。应用程序在本机操作系统上运行，管理其优先级和可用资源;后端在VM中运行，由AVE框架管理。我们引入一个管理器模块（在图2中突出显示）作为中间件来收集来自其他两个模块的信息，作业和结果，并进行卸载和作业分配决策。
![image](https://github.com/qpointwang/Mobile-Edge-Computing/blob/master/AVE-Autonomous-Vehicular-Edge-Computing/fig2.png)
在该车辆开始在道路上行驶之前，该框架的组件部署在每个车辆上。管理器模块预先安装在每辆车上，最好由车载系统供应商预安装。用户选择并安装应用程序。这样做的典型方法是从Internet安装应用程序; 但是，应用程序的安装方式和方式超出了本文的范围。后端可以与相应的应用程序一起安装（例如，用户可能想要可以在车辆上本地运行的应用程序）或独立部署（例如，公司可以在用户的车辆上部署后端以在路上提供服务）。

管理器模块由三个子模块组成：作业队列模块，资源管理模块和调度模块。作业队列模块为应用程序提供作业卸载接口，收集作业并在满足要求（在第IV节中讨论）时将它们放入调度程序中。资源管理模块控制后端可以使用的可用资源。请注意，安全，监视和紧急报告等CA任务不会卸载，并且在本地以最高优先级进行处理。除了CA所占用的资源外，其余资源可供后端使用。调度模块是管理器的核心。调度模块负责与其他节点通信，进行分配决策，发送作业和接收结果。在所提出的框架中，还需要全球定位系统（GPS）设备来调度模块以获得车辆的当前地理位置和速度。由于GPS设备被广泛安装，因此这一要求微不足道。

在我们的框架中建立的网络使用专用的短程通信（DSRC）标准，例如IEEE802.11p。这种类型的通信使得能够在不建立基本服务集的情况下快速建立链路。这减少了将数据发送到其他车辆所产生的开销。

#### C. Jobs
每个卸载的工作负载称为job。 卸载的工作负载可能发生在各种级别，例如功能，应用程序和虚拟机。为了符合这种多样性，这里将工作视为一般化实体。但是，对于用于调度的实际workload的建模，在我们的上下文中假设以下job特征：  
* 1）无上下文：这是在另一台机器上卸载和执行作业的基本要求。作业所依赖的资源文件要么在卸载之前分布在后端，要么被视为作业数据的一部分，并在卸载期间发送。这个特性意味着在卸载到管理器模块之前，应该在应用程序内处理作业的依赖性。应用程序用于分离作业的实现超出了本文的范围。但我们建议：对于依赖于另一个作业完成的作业，应用程序可以选择逐个卸载它们，每个都返回上一个作业的结果，或者将所有顺序作业打包成一个较大的独立作业。无论选择何种方法，缓存作业之间都不存在依赖关系，并且可以单独调度每个作业。例如，在CloneCloud情况下，每个作业都是一个挂起的线程，其所有相关的内存数据都传输到处理主机。
* 2）效用：不同的job通常对用户体验产生不同的影响，这些影响因完成时间而异。这里考虑了效用因子。每个作业都带有一个实用程序函数，它将完成时间映射到称为实用程序的累积实数值。该实用程序还结合了工作的重要性。
* 3）主机指定：我们假设每个节点不一定具备能够处理所有作业所需的所有功能。处理主机的要求也是拟议框架中考虑的因素之一。
* 4）简介(brief)：在分布式环境中，每个车辆必须向潜在的处理器提供关于其所请求的作业的一些信息，以用于处理时间估计和进一步调度。在带宽限制的车辆环境中，在这种查询中传输整个作业是不现实的。相反，每个应用程序都需要指定少量参数（我们称之为简要参数）来描述作业的工作量。这些参数的内容和格式由应用程序和相应的后端确定。

#### D. Neighbor Availability Index(邻居可用性指数)
为了帮助车辆以分布式方式做出决策，引入了称为邻居可用性指数（NAI）的值.NAI可用于指示在请求者的可到达区域内有多少潜在的辅助车辆。 虽然它们的可用资源可能不同，但这仍然可以作为对附近资源的粗略估计。 每辆车计算其NAI为可用于表示有多少可能的协助：  
![image](https://github.com/qpointwang/Mobile-Edge-Computing/blob/master/AVE-Autonomous-Vehicular-Edge-Computing/NAI.png)

这里，“idle”意味着邻居的资源管理器不使用它管理的可用资源处理任何作业。k指定邻居的跳数。因为根据现有研究，通过超过2跳的中继的通信是不稳定的，所以在NAI计算和进一步调度中忽略超过2跳的节点。φ是表示随着跳数增加而资源可用性衰落的因素。这里的“衰落”指的是随着跳数的增加，传输开销和失去连接的概率增加，这导致卸载的收益减少。在我们的模拟场景中测试，φ= 0.8是合适的，但是最合适的值可能在不同的实际情况中不同。

为了在需要时计算NAI，AVE在每辆车上建立一个NAI表以存储所需信息。表中的条目的格式为<车辆ID，空闲状态，跳数，到期时间>，并且当达到其到期时间时，将自动删除条目。更新此表的过程将在第IV节中进一步讨论。

### WORKFLOW

![image](https://github.com/qpointwang/Mobile-Edge-Computing/blob/master/AVE-Autonomous-Vehicular-Edge-Computing/fig3.png)

AVE框架的工作流程由两部分组成：主动定期信标和主动流程(active periodic beaconing and proactive flows)。 流程表示处理作业从到达到返回结果的过程。在这个框架中，我们将流程划分为四个主要阶段：作业缓存，发现，调度和数据传输，如图3所示。信息的细节和流程的阶段在本节的其余部分进行了解释。
